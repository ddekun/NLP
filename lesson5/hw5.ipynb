{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMFmfst1uG0znlHk4CLPpeZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ddekun/NLP/blob/lesson5/lesson5/hw5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Введение в обработку естественного языка"
      ],
      "metadata": {
        "id": "XVCl4SX0x7FS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Урок 5. Part-of-Speech разметка, NER, извлечение отношений"
      ],
      "metadata": {
        "id": "KSjEl0_Cx9Rl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Тема «POS-tagger и NER»**\n",
        "\n",
        "Задание 1. Написать теггер на данных с русским языком\n",
        "\n",
        "- проверить UnigramTagger, BigramTagger, TrigramTagger и их комбинации\n",
        "\n",
        "- написать свой теггер как на занятии, попробовать разные векторайзеры, добавить\n",
        "знание не только букв но и слов\n",
        "\n",
        "- сравнить все реализованные методы, сделать выводы"
      ],
      "metadata": {
        "id": "HjGhOb90ynEU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFT6fv1Ox5hb",
        "outputId": "a4ed7277-6e5e-4b51-dc9c-2e7f85d4154d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyconll\n",
            "  Downloading pyconll-3.2.0-py3-none-any.whl (27 kB)\n",
            "Installing collected packages: pyconll\n",
            "Successfully installed pyconll-3.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pyconll"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tag import DefaultTagger\n",
        "from nltk.tag import UnigramTagger\n",
        "from nltk.tag import BigramTagger, TrigramTagger\n",
        "from nltk.tag import RegexpTagger\n",
        "\n",
        "import pyconll"
      ],
      "metadata": {
        "id": "webAp5HBy4nS"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/master/ru_syntagrus-ud-train-a.conllu\n",
        "!wget https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/master/ru_syntagrus-ud-dev.conllu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dYJWqEG_y79G",
        "outputId": "c79dbd3a-7e71-429a-b70d-586498d287d2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-09-04 15:24:41--  https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/master/ru_syntagrus-ud-train-a.conllu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 40736581 (39M) [text/plain]\n",
            "Saving to: ‘ru_syntagrus-ud-train-a.conllu’\n",
            "\n",
            "ru_syntagrus-ud-tra 100%[===================>]  38.85M  54.4MB/s    in 0.7s    \n",
            "\n",
            "2023-09-04 15:27:19 (54.4 MB/s) - ‘ru_syntagrus-ud-train-a.conllu’ saved [40736581/40736581]\n",
            "\n",
            "--2023-09-04 15:27:19--  https://raw.githubusercontent.com/UniversalDependencies/UD_Russian-SynTagRus/master/ru_syntagrus-ud-dev.conllu\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14704579 (14M) [text/plain]\n",
            "Saving to: ‘ru_syntagrus-ud-dev.conllu’\n",
            "\n",
            "ru_syntagrus-ud-dev 100%[===================>]  14.02M  41.2MB/s    in 0.3s    \n",
            "\n",
            "2023-09-04 15:27:44 (41.2 MB/s) - ‘ru_syntagrus-ud-dev.conllu’ saved [14704579/14704579]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full_train = pyconll.load_from_file('/content/ru_syntagrus-ud-train-a.conllu')\n",
        "full_test = pyconll.load_from_file('/content/ru_syntagrus-ud-dev.conllu')"
      ],
      "metadata": {
        "id": "z2bvoTUSzAXW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fdata_train = []\n",
        "for sent in full_train[:]:\n",
        "    fdata_train.append([(token.form, token.upos) for token in sent])\n",
        "\n",
        "fdata_test = []\n",
        "for sent in full_test[:]:\n",
        "    fdata_test.append([(token.form, token.upos) for token in sent])\n",
        "\n",
        "fdata_sent_test = []\n",
        "for sent in full_test[:]:\n",
        "    for word in sent:\n",
        "        fdata_sent_test.append(word.form)"
      ],
      "metadata": {
        "id": "zEyj2r3qzCFq"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_SENT_LEN = max(len(sent) for sent in full_train)\n",
        "MAX_ORIG_TOKEN_LEN = max(len(token.form) for sent in full_train for token in sent)\n",
        "print('Максимальная длина предложения', MAX_SENT_LEN)\n",
        "print('Максимальная длина токена', MAX_ORIG_TOKEN_LEN)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sC9a0nAMzDom",
        "outputId": "c53ef70d-f4ec-4c54-a218-19e7b08dc196"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Максимальная длина предложения 194\n",
            "Максимальная длина токена 31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "unigram_tagger = UnigramTagger(fdata_train)\n",
        "unigram_tagger.evaluate(fdata_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzfPvauxzFAK",
        "outputId": "0771e350-573a-4e0c-8cfc-ffc5d46dd97e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-7-b70f333e48c5>:2: DeprecationWarning: \n",
            "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
            "  instead.\n",
            "  unigram_tagger.evaluate(fdata_test)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.823732013802982"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bigram_tagger = BigramTagger(fdata_train, backoff=unigram_tagger)\n",
        "bigram_tagger.evaluate(fdata_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZkchPVEzGaZ",
        "outputId": "5ca2475a-5185-4b3f-e6bd-2c2b893ddc13"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-8-be35a56830c0>:2: DeprecationWarning: \n",
            "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
            "  instead.\n",
            "  bigram_tagger.evaluate(fdata_test)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8292792499511688"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trigram_tagger = TrigramTagger(fdata_train, backoff=unigram_tagger)\n",
        "trigram_tagger.evaluate(fdata_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXG5EjdhzJQS",
        "outputId": "f0e7e7c6-d9f9-48f0-d40a-d32c20dac38b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-1246b3405b88>:2: DeprecationWarning: \n",
            "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
            "  instead.\n",
            "  trigram_tagger.evaluate(fdata_test)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.828550035809623"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trigram_tagger = TrigramTagger(fdata_train, backoff=bigram_tagger)\n",
        "trigram_tagger.evaluate(fdata_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xtuT3FcnzMIR",
        "outputId": "14e21a9d-036a-40af-89a0-6eb3f7a83c17"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-10-792eb0e8a39b>:2: DeprecationWarning: \n",
            "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
            "  instead.\n",
            "  trigram_tagger.evaluate(fdata_test)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8291425222996289"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def backoff_tagger(train_sents, tagger_classes, backoff=None):\n",
        "    for cls in tagger_classes:\n",
        "        backoff = cls(train_sents, backoff=backoff)\n",
        "    return backoff\n",
        "\n",
        "\n",
        "backoff = DefaultTagger('NN')\n",
        "tag = backoff_tagger(fdata_train,\n",
        "                     [UnigramTagger, BigramTagger, TrigramTagger],\n",
        "                     backoff = backoff)\n",
        "\n",
        "tag.evaluate(fdata_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "olgLHp0EzMth",
        "outputId": "0d50214d-f27c-4fc8-af67-100afbacaf84"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-4f2b35143c69>:12: DeprecationWarning: \n",
            "  Function evaluate() has been deprecated.  Use accuracy(gold)\n",
            "  instead.\n",
            "  tag.evaluate(fdata_test)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.827905462595221"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_token = []\n",
        "train_label = []\n",
        "for sent in fdata_train[:]:\n",
        "    for token in sent:\n",
        "        train_token.append(token[0])\n",
        "        train_label.append('NO_TAG' if token[1] is None else token[1])\n",
        "\n",
        "test_token = []\n",
        "test_label = []\n",
        "for sent in fdata_test[:]:\n",
        "    for token in sent:\n",
        "        test_token.append(token[0])\n",
        "        test_label.append('NO_TAG' if token[1] is None else token[1])"
      ],
      "metadata": {
        "id": "ZI4MwHEQzPse"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer, HashingVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "X3S_PIUXzQog"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()\n",
        "train_enc_labels = le.fit_transform(train_label)"
      ],
      "metadata": {
        "id": "r4sbXaPOzQll"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "le.classes_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3c4OCC7CzQib",
        "outputId": "4caf14aa-2d52-425f-db8a-ae090442f613"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['ADJ', 'ADP', 'ADV', 'AUX', 'CCONJ', 'DET', 'INTJ', 'NOUN',\n",
              "       'NO_TAG', 'NUM', 'PART', 'PRON', 'PROPN', 'PUNCT', 'SCONJ', 'SYM',\n",
              "       'VERB', 'X'], dtype='<U6')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hvectorizer = HashingVectorizer(ngram_range=(1, 4), analyzer='char', n_features=100)"
      ],
      "metadata": {
        "id": "9xxFBZ1RzQfQ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for number, element in enumerate(test_token):\n",
        "    if element == None:\n",
        "        test_token[number] = 'Договор'"
      ],
      "metadata": {
        "id": "iOoorlVvzQbp"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = hvectorizer.fit_transform(train_token)\n",
        "X_test = hvectorizer.transform(test_token)\n",
        "\n",
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8ufowcyzQXw",
        "outputId": "5b74c218-417c-4e3c-effd-77225a5451e6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(426182, 100)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "xgb_model = XGBClassifier()"
      ],
      "metadata": {
        "id": "1klm2D03zb1U"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "xgb_model.fit(X_train, train_enc_labels)"
      ],
      "metadata": {
        "id": "CJK6wJcizcaH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = xgb_model.predict(X_test)"
      ],
      "metadata": {
        "id": "vK16cnrfzcXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
        "test_enc_labels = le.fit_transform(test_label)\n",
        "\n",
        "print(classification_report(test_enc_labels, pred))"
      ],
      "metadata": {
        "id": "RmPyaknZzcUE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Задание 2. Проверить, насколько хорошо работает NER\n",
        "Данные брать из http://www.labinform.ru/pub/named_entities/\n",
        "\n",
        "- проверить NER из nltk/spacy/deeppavlov.\n",
        "- написать свой NER, попробовать разные подходы.\n",
        "   - передаём в сетку токен и его соседей.\n",
        "   - передаём в сетку только токен.\n",
        "   - свой вариант.\n",
        "- сравнить свои реализованные подходы на качество — вывести precision/recall/- f1_score."
      ],
      "metadata": {
        "id": "eK1Unqbuzno3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install corus\n",
        "!pip install razdel"
      ],
      "metadata": {
        "id": "3JX4sf8TzixE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget http://www.labinform.ru/pub/named_entities/collection5.zip"
      ],
      "metadata": {
        "id": "-KU_NyLoziuA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip collection5.zip"
      ],
      "metadata": {
        "id": "Rkiy2x7dziqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from corus import load_ne5\n",
        "\n",
        "path_col5 = 'Collection5/'\n",
        "records = load_ne5(path_col5)"
      ],
      "metadata": {
        "id": "s0F7C4uWzind"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from razdel import tokenize\n",
        "\n",
        "words_docs = []\n",
        "for idx, rec in enumerate(records):\n",
        "    words = []\n",
        "    for token in tokenize(rec.text):\n",
        "        type_ent = 'OUT'\n",
        "        for ent in rec.spans:\n",
        "            if (token.start >= ent.start) and (token.stop <= ent.stop):\n",
        "                type_ent = ent.type\n",
        "                break\n",
        "        words.append([token.text, type_ent])\n",
        "    words_docs.extend(words)"
      ],
      "metadata": {
        "id": "5KwszWtdziAw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_words = pd.DataFrame(words_docs, columns=['word', 'tag'])\n",
        "df_words['tag'].value_counts()"
      ],
      "metadata": {
        "id": "1cjlcLS00HiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words_list = []\n",
        "for word in words_docs:\n",
        "    words_list.append(word[0])\n",
        "\n",
        "words_list[:10]"
      ],
      "metadata": {
        "id": "svFulHkE0HfW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "\n",
        "nltk_pos_tags = nltk.pos_tag(words_list)"
      ],
      "metadata": {
        "id": "QkR9RSTw0HcZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('maxent_ne_chunker')\n",
        "nltk.download('words')\n",
        "\n",
        "chunks = nltk.ne_chunk(nltk_pos_tags, binary=False)"
      ],
      "metadata": {
        "id": "ogzjt5d50HZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pos_tag = nltk.pos_tag(words_list)\n",
        "chunk = nltk.ne_chunk(pos_tag, binary=False)\n",
        "entities = []\n",
        "labels = []\n",
        "for chunk in chunks:\n",
        "    if hasattr(chunk, 'label'):\n",
        "        for c in chunk:\n",
        "            entities.append(c[0])\n",
        "            labels.append(chunk.label())\n",
        "    else:\n",
        "        entities.append(chunk[0])\n",
        "        labels.append('OUT')"
      ],
      "metadata": {
        "id": "sO5CSuKI0HV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "entities_labels = list(zip(entities, labels))\n",
        "entities_df = pd.DataFrame(entities_labels, columns = ['Entities', 'Labels'])\n",
        "\n",
        "entities_df"
      ],
      "metadata": {
        "id": "Pvlq0bZh0HSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_words['nltk_ner'] = entities_df['Labels']\n",
        "df_words"
      ],
      "metadata": {
        "id": "Qorw1aUB0Qad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ner_metrics(df, true_tag, ner_tag, column_name_1, column_name_2):\n",
        "    right = 0\n",
        "    fault = 0\n",
        "    fault_2 = 0\n",
        "\n",
        "    for index, person in  df.iterrows():\n",
        "        if (person[column_name_1] == true_tag) & (person[column_name_2] == ner_tag):\n",
        "            right += 1\n",
        "        elif (person[column_name_1] == true_tag) & (person[column_name_2] !=  ner_tag):\n",
        "            fault += 1\n",
        "        elif (person[column_name_1] != true_tag) & (person[column_name_2] ==  ner_tag):\n",
        "            fault_2 += 1\n",
        "    precision = right / (right+fault_2)\n",
        "    recall = right / (right+fault)\n",
        "    f1 = (2*precision*recall) / (precision+recall)\n",
        "    return print(f'precision = {precision}, recall = {recall}, f1_score = {f1}')"
      ],
      "metadata": {
        "id": "Q8OqsUyR0S8T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ner_metrics(df_words, 'PER', 'PERSON', 'tag', 'nltk_ner')"
      ],
      "metadata": {
        "id": "2R3rjS600S5V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ner_metrics(df_words, 'ORG', 'ORGANIZATION', 'tag', 'nltk_ner')"
      ],
      "metadata": {
        "id": "HfjHM6oA0S2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download ru_core_news_md"
      ],
      "metadata": {
        "id": "9rjlUYa40XmC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load('ru_core_news_md')\n",
        "\n",
        "labels=[]\n",
        "i=0\n",
        "for word in words_list:\n",
        "    spacy_ner = nlp(word)\n",
        "    if spacy_ner.__getitem__(0).ent_type_ == '':\n",
        "        labels.append('OUT')\n",
        "    else:\n",
        "        labels.append(spacy_ner.__getitem__(0).ent_type_)\n",
        "    i+=1\n",
        "    if (i % 10000) == 0:\n",
        "        print(f'обработано {i} слов')"
      ],
      "metadata": {
        "id": "vYnLzzL20bh9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_words['spacy_ner'] = labels\n",
        "df_words"
      ],
      "metadata": {
        "id": "ZtOmgCgX0dRK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ner_metrics(df_words, 'PER', 'PER', 'tag', 'spacy_ner')"
      ],
      "metadata": {
        "id": "vvegvBKT0fq6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "ner_metrics(df_words, 'ORG', 'ORG', 'tag', 'spacy_ner')"
      ],
      "metadata": {
        "id": "R5igpFdF0fnj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ner_metrics(df_words, 'LOC', 'LOC', 'tag', 'spacy_ner')"
      ],
      "metadata": {
        "id": "kdEuE5tC0fkH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}